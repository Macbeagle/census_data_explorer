return(data)
}
download_file <- function(url, dest_path, extract_path, file_name){
# Ensure the destination directory exists
if (!dir.exists(dest_path)) {
dir.create(dest_path, recursive = TRUE)
}
full_dest_path <- file.path(dest_path, file_name)
# Adjust extract_path to not append file_name directly
GET(url, write_disk(full_dest_path, overwrite = TRUE))
if (grepl(".zip$", full_dest_path)){
unzip_file(full_dest_path, extract_path)
file.remove(full_dest_path)
}
}
url <- "https://api.data.abs.gov.au/data/ABS,POP_PROJ_REGION,1.0.0/32+31+3.2+1+3.TT.....A?startPeriod=2022&format=csv"
download_file(url, here("data"), here("data"), "ABS_PROJ_REGION_QLD.csv")
#import as dataframe
data <- read_csv(here("data", "ABS_PROJ_REGION_QLD.csv"))
data_df <- as.data.frame(data)
#fertility = 3/2/1
#expectancy = 1/2
#migration = 1/2/3/4
#interstate = 1/2/3
#Rest of qld =3
#brisbane = 32
#select only the REGION, SEX_ABS, MORTALITY, NOM, NIM, TIME_PERIOD, OBS_VALUE columns
colnames(data_df)
data_df <- data_df %>% select(REGION, FERTILITY, SEX_ABS, MORTALITY, NOM, NIM, TIME_PERIOD, OBS_VALUE)
#split the data by region, region 32 is brisbane, region 3 is rest of qld and remove the REGION column
#create a primary key column using ssh for the data using the OBS_VALUE column
data_df$GROWTH_KEY <- md5(as.character(data_df$OBS_VALUE))
brisbane_df <- data_df %>% filter(REGION == 32) %>% select(-REGION)
rest_of_qld_df <- data_df %>% filter(REGION == 3) %>% select(-REGION)
brisbane_df_filtered_1 <- brisbane_df %>% filter(FERTILITY == 1, MORTALITY == 1, NOM == 1, NIM == 1, SEX_ABS == 3)
# Filter Brisbane data for MORTALITY of 2, NOM of 2, NIM of 2, and SEX_ABS of 3
brisbane_df_filtered_2 <- brisbane_df %>% filter(FERTILITY == 2, MORTALITY == 2, NOM == 2, NIM == 2, SEX_ABS == 3)
brisbane_df_filtered_3 <- brisbane_df %>% filter(FERTILITY == 3, MORTALITY == 2, NOM == 3, NIM == 3, SEX_ABS == 3)
# Combine the filtered data and add a new column to distinguish the groups
brisbane_df_filtered_1$Group <- "FERTILITY = 1, MORTALITY=1, NOM=1, NIM=1"
brisbane_df_filtered_2$Group <- "FERTILITY = 2,MORTALITY=2, NOM=2, NIM=2"
brisbane_df_filtered_3$Group <- "FERTILITY = 3,MORTALITY=2, NOM=3, NIM=3"
combined_df <- bind_rows(brisbane_df_filtered_1, brisbane_df_filtered_2, brisbane_df_filtered_3)
# Plot the filtered data
ggplot(combined_df, aes(x = TIME_PERIOD, y = OBS_VALUE, color = Group)) +
geom_smooth(method = "loess") +  # Use a smooth plot
labs(title = "Population over next 50 years in Brisbane",
x = "Time Period",
y = "Population") +
theme_minimal()
View(data_df)
View(data_df)
library(httr)
library(readr)
library(readxl)
library(here)
library(dplyr)
library(ggplot2)
library(openssl)
unzip_file <- function(zip_path, dest_path){
unzip(zip_path, exdir = dest_path)
}
import_csv <- function(file_path) {
data <- read_csv(file_path)
return(data)
}
download_file <- function(url, dest_path, extract_path, file_name){
# Ensure the destination directory exists
if (!dir.exists(dest_path)) {
dir.create(dest_path, recursive = TRUE)
}
full_dest_path <- file.path(dest_path, file_name)
# Adjust extract_path to not append file_name directly
GET(url, write_disk(full_dest_path, overwrite = TRUE))
if (grepl(".zip$", full_dest_path)){
unzip_file(full_dest_path, extract_path)
file.remove(full_dest_path)
}
}
url <- "https://api.data.abs.gov.au/data/ABS,POP_PROJ_REGION,1.0.0/32+31+3.2+1+3.TT.....A?startPeriod=2022&format=csv"
download_file(url, here("data"), here("data"), "ABS_PROJ_REGION_QLD.csv")
#import as dataframe
data <- read_csv(here("data", "ABS_PROJ_REGION_QLD.csv"))
data_df <- as.data.frame(data)
#fertility = 3/2/1
#expectancy = 1/2
#migration = 1/2/3/4
#interstate = 1/2/3
#Rest of qld =3
#brisbane = 32
#select only the REGION, SEX_ABS, MORTALITY, NOM, NIM, TIME_PERIOD, OBS_VALUE columns
colnames(data_df)
data_df <- data_df %>% select(REGION, FERTILITY, SEX_ABS, MORTALITY, NOM, NIM, TIME_PERIOD, OBS_VALUE)
#split the data by region, region 32 is brisbane, region 3 is rest of qld and remove the REGION column
#create a primary key column using ssh for the data using the OBS_VALUE column
data_df$GROWTH_KEY <- md5(as.character(data_df$OBS_VALUE))
data_df$DATE_RETRIEVED <- today()
library(httr)
library(readr)
library(readxl)
library(here)
library(dplyr)
library(ggplot2)
library(openssl)
unzip_file <- function(zip_path, dest_path){
unzip(zip_path, exdir = dest_path)
}
import_csv <- function(file_path) {
data <- read_csv(file_path)
return(data)
}
download_file <- function(url, dest_path, extract_path, file_name){
# Ensure the destination directory exists
if (!dir.exists(dest_path)) {
dir.create(dest_path, recursive = TRUE)
}
full_dest_path <- file.path(dest_path, file_name)
# Adjust extract_path to not append file_name directly
GET(url, write_disk(full_dest_path, overwrite = TRUE))
if (grepl(".zip$", full_dest_path)){
unzip_file(full_dest_path, extract_path)
file.remove(full_dest_path)
}
}
url <- "https://api.data.abs.gov.au/data/ABS,POP_PROJ_REGION,1.0.0/32+31+3.2+1+3.TT.....A?startPeriod=2022&format=csv"
download_file(url, here("data"), here("data"), "ABS_PROJ_REGION_QLD.csv")
#import as dataframe
data <- read_csv(here("data", "ABS_PROJ_REGION_QLD.csv"))
data_df <- as.data.frame(data)
#fertility = 3/2/1
#expectancy = 1/2
#migration = 1/2/3/4
#interstate = 1/2/3
#Rest of qld =3
#brisbane = 32
#select only the REGION, SEX_ABS, MORTALITY, NOM, NIM, TIME_PERIOD, OBS_VALUE columns
colnames(data_df)
data_df <- data_df %>% select(REGION, FERTILITY, SEX_ABS, MORTALITY, NOM, NIM, TIME_PERIOD, OBS_VALUE)
#split the data by region, region 32 is brisbane, region 3 is rest of qld and remove the REGION column
#create a primary key column using ssh for the data using the OBS_VALUE column
data_df$GROWTH_KEY <- md5(as.character(data_df$OBS_VALUE))
data_df$DATE_RETRIEVED <- sys.Date()
library(httr)
library(readr)
library(readxl)
library(here)
library(dplyr)
library(ggplot2)
library(openssl)
library(tidyverse)
unzip_file <- function(zip_path, dest_path){
unzip(zip_path, exdir = dest_path)
}
import_csv <- function(file_path) {
data <- read_csv(file_path)
return(data)
}
download_file <- function(url, dest_path, extract_path, file_name){
# Ensure the destination directory exists
if (!dir.exists(dest_path)) {
dir.create(dest_path, recursive = TRUE)
}
full_dest_path <- file.path(dest_path, file_name)
# Adjust extract_path to not append file_name directly
GET(url, write_disk(full_dest_path, overwrite = TRUE))
if (grepl(".zip$", full_dest_path)){
unzip_file(full_dest_path, extract_path)
file.remove(full_dest_path)
}
}
url <- "https://api.data.abs.gov.au/data/ABS,POP_PROJ_REGION,1.0.0/32+31+3.2+1+3.TT.....A?startPeriod=2022&format=csv"
download_file(url, here("data"), here("data"), "ABS_PROJ_REGION_QLD.csv")
#import as dataframe
data <- read_csv(here("data", "ABS_PROJ_REGION_QLD.csv"))
data_df <- as.data.frame(data)
#fertility = 3/2/1
#expectancy = 1/2
#migration = 1/2/3/4
#interstate = 1/2/3
#Rest of qld =3
#brisbane = 32
#select only the REGION, SEX_ABS, MORTALITY, NOM, NIM, TIME_PERIOD, OBS_VALUE columns
colnames(data_df)
data_df <- data_df %>% select(REGION, FERTILITY, SEX_ABS, MORTALITY, NOM, NIM, TIME_PERIOD, OBS_VALUE)
#split the data by region, region 32 is brisbane, region 3 is rest of qld and remove the REGION column
#create a primary key column using ssh for the data using the OBS_VALUE column
data_df$GROWTH_KEY <- md5(as.character(data_df$OBS_VALUE))
data_df$DATE_RETRIEVED <- sys.Date()
library(httr)
library(readr)
library(readxl)
library(here)
library(dplyr)
library(ggplot2)
library(openssl)
library(tidyverse)
unzip_file <- function(zip_path, dest_path){
unzip(zip_path, exdir = dest_path)
}
import_csv <- function(file_path) {
data <- read_csv(file_path)
return(data)
}
download_file <- function(url, dest_path, extract_path, file_name){
# Ensure the destination directory exists
if (!dir.exists(dest_path)) {
dir.create(dest_path, recursive = TRUE)
}
full_dest_path <- file.path(dest_path, file_name)
# Adjust extract_path to not append file_name directly
GET(url, write_disk(full_dest_path, overwrite = TRUE))
if (grepl(".zip$", full_dest_path)){
unzip_file(full_dest_path, extract_path)
file.remove(full_dest_path)
}
}
url <- "https://api.data.abs.gov.au/data/ABS,POP_PROJ_REGION,1.0.0/32+31+3.2+1+3.TT.....A?startPeriod=2022&format=csv"
download_file(url, here("data"), here("data"), "ABS_PROJ_REGION_QLD.csv")
#import as dataframe
data <- read_csv(here("data", "ABS_PROJ_REGION_QLD.csv"))
data_df <- as.data.frame(data)
#fertility = 3/2/1
#expectancy = 1/2
#migration = 1/2/3/4
#interstate = 1/2/3
#Rest of qld =3
#brisbane = 32
#select only the REGION, SEX_ABS, MORTALITY, NOM, NIM, TIME_PERIOD, OBS_VALUE columns
colnames(data_df)
data_df <- data_df %>% select(REGION, FERTILITY, SEX_ABS, MORTALITY, NOM, NIM, TIME_PERIOD, OBS_VALUE)
#split the data by region, region 32 is brisbane, region 3 is rest of qld and remove the REGION column
#create a primary key column using ssh for the data using the OBS_VALUE column
data_df$GROWTH_KEY <- md5(as.character(data_df$OBS_VALUE))
data_df$DATE_RETRIEVED <- today()
brisbane_df <- data_df %>% filter(REGION == 32) %>% select(-REGION)
rest_of_qld_df <- data_df %>% filter(REGION == 3) %>% select(-REGION)
brisbane_df_filtered_1 <- brisbane_df %>% filter(FERTILITY == 1, MORTALITY == 1, NOM == 1, NIM == 1, SEX_ABS == 3)
# Filter Brisbane data for MORTALITY of 2, NOM of 2, NIM of 2, and SEX_ABS of 3
brisbane_df_filtered_2 <- brisbane_df %>% filter(FERTILITY == 2, MORTALITY == 2, NOM == 2, NIM == 2, SEX_ABS == 3)
brisbane_df_filtered_3 <- brisbane_df %>% filter(FERTILITY == 3, MORTALITY == 2, NOM == 3, NIM == 3, SEX_ABS == 3)
# Combine the filtered data and add a new column to distinguish the groups
brisbane_df_filtered_1$Group <- "FERTILITY = 1, MORTALITY=1, NOM=1, NIM=1"
brisbane_df_filtered_2$Group <- "FERTILITY = 2,MORTALITY=2, NOM=2, NIM=2"
brisbane_df_filtered_3$Group <- "FERTILITY = 3,MORTALITY=2, NOM=3, NIM=3"
combined_df <- bind_rows(brisbane_df_filtered_1, brisbane_df_filtered_2, brisbane_df_filtered_3)
# Plot the filtered data
ggplot(combined_df, aes(x = TIME_PERIOD, y = OBS_VALUE, color = Group)) +
geom_smooth(method = "loess") +  # Use a smooth plot
labs(title = "Population over next 50 years in Brisbane",
x = "Time Period",
y = "Population") +
theme_minimal()
library(httr)
library(readr)
library(readxl)
library(here)
library(dplyr)
library(ggplot2)
library(openssl)
library(tidyverse)
unzip_file <- function(zip_path, dest_path){
unzip(zip_path, exdir = dest_path)
}
import_csv <- function(file_path) {
data <- read_csv(file_path)
return(data)
}
download_file <- function(url, dest_path, extract_path, file_name){
# Ensure the destination directory exists
if (!dir.exists(dest_path)) {
dir.create(dest_path, recursive = TRUE)
}
full_dest_path <- file.path(dest_path, file_name)
# Adjust extract_path to not append file_name directly
GET(url, write_disk(full_dest_path, overwrite = TRUE))
if (grepl(".zip$", full_dest_path)){
unzip_file(full_dest_path, extract_path)
file.remove(full_dest_path)
}
}
url <- "https://api.data.abs.gov.au/data/ABS,POP_PROJ_REGION,1.0.0/32+31+3.2+1+3.TT.....A?startPeriod=2022&format=csv"
download_file(url, here("data"), here("data"), "ABS_PROJ_REGION_QLD.csv")
#import as dataframe
data <- read_csv(here("data", "ABS_PROJ_REGION_QLD.csv"))
data_df <- as.data.frame(data)
#fertility = 3/2/1
#expectancy = 1/2
#migration = 1/2/3/4
#interstate = 1/2/3
#Rest of qld =3
#brisbane = 32
#select only the REGION, SEX_ABS, MORTALITY, NOM, NIM, TIME_PERIOD, OBS_VALUE columns
colnames(data_df)
data_df <- data_df %>% select(REGION, FERTILITY, SEX_ABS, MORTALITY, NOM, NIM, TIME_PERIOD, OBS_VALUE)
#split the data by region, region 32 is brisbane, region 3 is rest of qld and remove the REGION column
#create a primary key column using ssh for the data using the OBS_VALUE column
data_df$GROWTH_KEY <- md5(as.character(data_df$OBS_VALUE))
data_df$DATE_RETRIEVED <- today()
brisbane_df <- data_df %>% filter(REGION == 32) %>% select(-REGION)
rest_of_qld_df <- data_df %>% filter(REGION == 3) %>% select(-REGION)
brisbane_df_filtered_1 <- brisbane_df %>% filter(FERTILITY == 1, MORTALITY == 1, NOM == 1, NIM == 1, SEX_ABS == 3)
# Filter Brisbane data for MORTALITY of 2, NOM of 2, NIM of 2, and SEX_ABS of 3
brisbane_df_filtered_2 <- brisbane_df %>% filter(FERTILITY == 2, MORTALITY == 2, NOM == 2, NIM == 2, SEX_ABS == 3)
brisbane_df_filtered_3 <- brisbane_df %>% filter(FERTILITY == 3, MORTALITY == 2, NOM == 3, NIM == 3, SEX_ABS == 3)
# Combine the filtered data and add a new column to distinguish the groups
brisbane_df_filtered_1$Group <- "FERTILITY = 1, MORTALITY=1, NOM=1, NIM=1"
brisbane_df_filtered_2$Group <- "FERTILITY = 2,MORTALITY=2, NOM=2, NIM=2"
brisbane_df_filtered_3$Group <- "FERTILITY = 3,MORTALITY=2, NOM=3, NIM=3"
combined_df <- bind_rows(brisbane_df_filtered_1, brisbane_df_filtered_2, brisbane_df_filtered_3)
# Plot the filtered data
ggplot(combined_df, aes(x = TIME_PERIOD, y = OBS_VALUE, color = Group)) +
geom_smooth(method = "loess") +  # Use a smooth plot
labs(title = "Population over next 50 years in Brisbane",
x = "Time Period",
y = "Population") +
theme_minimal()
libr_used
library()
library(httr)
#library(readr)
library(readxl)
library(here)
library(dplyr)
library(ggplot2)
library(openssl)
library(tidyverse)
unzip_file <- function(zip_path, dest_path){
unzip(zip_path, exdir = dest_path)
}
import_csv <- function(file_path) {
data <- read_csv(file_path)
return(data)
}
download_file <- function(url, dest_path, extract_path, file_name){
# Ensure the destination directory exists
if (!dir.exists(dest_path)) {
dir.create(dest_path, recursive = TRUE)
}
full_dest_path <- file.path(dest_path, file_name)
# Adjust extract_path to not append file_name directly
GET(url, write_disk(full_dest_path, overwrite = TRUE))
if (grepl(".zip$", full_dest_path)){
unzip_file(full_dest_path, extract_path)
file.remove(full_dest_path)
}
}
url <- "https://api.data.abs.gov.au/data/ABS,POP_PROJ_REGION,1.0.0/32+31+3.2+1+3.TT.....A?startPeriod=2022&format=csv"
download_file(url, here("data"), here("data"), "ABS_PROJ_REGION_QLD.csv")
#import as dataframe
data <- read_csv(here("data", "ABS_PROJ_REGION_QLD.csv"))
data_df <- as.data.frame(data)
#fertility = 3/2/1
#expectancy = 1/2
#migration = 1/2/3/4
#interstate = 1/2/3
#Rest of qld =3
#brisbane = 32
#select only the REGION, SEX_ABS, MORTALITY, NOM, NIM, TIME_PERIOD, OBS_VALUE columns
colnames(data_df)
data_df <- data_df %>% select(REGION, FERTILITY, SEX_ABS, MORTALITY, NOM, NIM, TIME_PERIOD, OBS_VALUE)
#split the data by region, region 32 is brisbane, region 3 is rest of qld and remove the REGION column
#create a primary key column using ssh for the data using the OBS_VALUE column
data_df$GROWTH_KEY <- md5(as.character(data_df$OBS_VALUE))
data_df$DATE_RETRIEVED <- today()
brisbane_df <- data_df %>% filter(REGION == 32) %>% select(-REGION)
rest_of_qld_df <- data_df %>% filter(REGION == 3) %>% select(-REGION)
brisbane_df_filtered_1 <- brisbane_df %>% filter(FERTILITY == 1, MORTALITY == 1, NOM == 1, NIM == 1, SEX_ABS == 3)
# Filter Brisbane data for MORTALITY of 2, NOM of 2, NIM of 2, and SEX_ABS of 3
brisbane_df_filtered_2 <- brisbane_df %>% filter(FERTILITY == 2, MORTALITY == 2, NOM == 2, NIM == 2, SEX_ABS == 3)
brisbane_df_filtered_3 <- brisbane_df %>% filter(FERTILITY == 3, MORTALITY == 2, NOM == 3, NIM == 3, SEX_ABS == 3)
# Combine the filtered data and add a new column to distinguish the groups
brisbane_df_filtered_1$Group <- "FERTILITY = 1, MORTALITY=1, NOM=1, NIM=1"
brisbane_df_filtered_2$Group <- "FERTILITY = 2,MORTALITY=2, NOM=2, NIM=2"
brisbane_df_filtered_3$Group <- "FERTILITY = 3,MORTALITY=2, NOM=3, NIM=3"
combined_df <- bind_rows(brisbane_df_filtered_1, brisbane_df_filtered_2, brisbane_df_filtered_3)
# Plot the filtered data
ggplot(combined_df, aes(x = TIME_PERIOD, y = OBS_VALUE, color = Group)) +
geom_smooth(method = "loess") +  # Use a smooth plot
labs(title = "Population over next 50 years in Brisbane",
x = "Time Period",
y = "Population") +
theme_minimal()
View(data_df)
list.files(here())
library(readxl)
library(tidyverse)
library(openssl)
library(dplyr)
library(data.table)
library(here)
base_path <- here()
scripts_path <- here("Scripts", "data_Download.R")
source(scripts_path)
install.packages("palmerpenguins")
install.packages("quarto")
shiny::runApp('abs_app')
runApp('abs_app')
runApp('abs_app')
install.packages("purrr")
shiny::runApp('abs_app')
runApp('abs_app')
runApp('abs_app')
runApp('abs_app')
runApp('abs_app')
runApp('abs_app')
runApp('abs_app')
runApp('abs_app')
runApp('abs_app')
runApp('abs_app')
runApp('abs_app')
runApp('abs_app')
runApp('abs_app')
runApp('abs_app')
runApp('abs_app')
runApp('abs_app')
runApp('abs_app')
search <- as.character(data[selected_row, 1])
search <- as.character(data[4, 1])
data <- read.csv(here("data", file, "Metadata", "data_def_tables.csv"))
print(search)
print(search)
combined_data <- retrieve_table(search, file)
retrieve_table <- function(search_value, activeData) {
datafiles <- here("data", activeData, "Tables")
search_2 <- search_value
file_names <- list.files(datafiles)
table_index <- data.table(V1 = file_names)
# Get a list of all files in the Tables directory
table_index <- tibble(V1 = list.files(datafiles))
# Check the lengths of the vectors
print(paste("Length of table_index$V1:", length(table_index$V1)))
print(paste("Length of search_value:", length(search_value)))
# Search for the search_value in the table_index
print(table_index, n = Inf)
print(search_value)
#search for the search_value in the table_index
index <- str_detect(table_index$V1, search_2)
#index <- grep(search_value, table_index$V1, fixed = TRUE)
print("Index:")
print(index)
file_paths <- file.path(datafiles, table_index$V1[index])
print("file paths:")
print(file_paths)
combined_df <- map_dfr(file_paths, read.csv)
return(combined_df)
}
file <- "Census_2021_IP_IARE_TAS"
data <- read.csv(here("data", file, "Metadata", "data_def_tables.csv"))
search <- as.character(data[4, 1])
print(search)
combined_data <- retrieve_table(search, file)
table_data(combined_data)
print(combined_data)
retrieve_table <- function(search_value, activeData) {
datafiles <- here("data", activeData, "Tables")
search_2 <- search_value
file_names <- list.files(datafiles)
table_index <- data.table(V1 = file_names)
# Get a list of all files in the Tables directory
table_index <- tibble(V1 = list.files(datafiles))
# Check the lengths of the vectors
print(paste("Length of table_index$V1:", length(table_index$V1)))
print(paste("Length of search_value:", length(search_value)))
# Search for the search_value in the table_index
print(table_index, n = Inf)
print(search_value)
#search for the search_value in the table_index
index <- str_detect(table_index$V1, search_2)
#index <- grep(search_value, table_index$V1, fixed = TRUE)
print("Index:")
print(index)
file_paths <- file.path(datafiles, table_index$V1[index])
print("file paths:")
print(file_paths)
combined_df <- map_dfr(file_paths, read.csv)
return(combined_df)
}
file <- "Census_2021_IP_IARE_TAS"
data <- read.csv(here("data", file, "Metadata", "data_def_tables.csv"))
search <- as.character(data[4, 1])
print(search)
combined_data <- retrieve_table(search, file)
print(combined_data)
runApp('abs_app')
runApp('abs_app')
runApp('abs_app')
runApp('abs_app')
runApp('abs_app')
runApp('abs_app')
runApp('abs_app')
runApp('abs_app')
runApp('abs_app')
runApp('abs_app')
refresh_file_list(output, ns)
runApp('abs_app')
runApp('abs_app')
runApp('abs_app')
runApp('abs_app')
runApp('abs_app')
runApp('abs_app')
runApp('abs_app')
runApp('abs_app')
runApp('abs_app')
runApp('abs_app')
runApp('abs_app')
runApp('abs_app')
runApp('abs_app')
runApp('abs_app')
runApp('abs_app')
data <- read.csv(here("data", file, "Metadata", "data_def_columns.csv"))
runApp('abs_app')
runApp('abs_app')
